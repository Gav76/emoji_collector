# ğŸ® Emoji Collector

A gamified real-time face tracking web application that detects facial expressions and matches them to emojis. Built with MediaPipe Face Mesh and TypeScript.

## Features

- ğŸ¯ Real-time face detection and tracking with 150+ facial landmarks
- ğŸ˜Š 12 different facial expression detection (Neutral, Happy, Very Happy, Sad, Surprised, Angry, Wink, Kiss, Tongue Out, Thinking, Sleepy, Confused)
- ğŸ® Gamified emoji collection with counters
- ğŸ¨ Dynamic border colors indicating head direction (LEFT, RIGHT, UP, DOWN, CENTER)
- ğŸ”’ Client-side processing (privacy-focused - no data sent to servers)
- ğŸ“± Fully responsive design (480px to 1200px+)
- â˜ï¸ AWS deployment ready (S3 + CloudFront)
- âœ… Property-based testing for correctness

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         User Interface                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Emoji Collection Grid (2 rows Ã— 6 columns)              â”‚  â”‚
â”‚  â”‚  [ğŸ˜ Neutral] [ğŸ™‚ Happy] [ğŸ˜„ Very Happy] [ğŸ˜¢ Sad] ...    â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Video Canvas (640Ã—480) + Facial Landmarks Overlay       â”‚  â”‚
â”‚  â”‚  [Dynamic Border Color: LEFT/RIGHT/UP/DOWN/CENTER]       â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Status: Direction | Emoji | FPS                         â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â–²
                              â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ApplicationController                       â”‚
â”‚  â€¢ Orchestrates all components                                â”‚
â”‚  â€¢ Manages render loop (30 FPS target)                        â”‚
â”‚  â€¢ Handles state management                                   â”‚
â”‚  â€¢ Error handling and recovery                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚              â”‚              â”‚
    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
    â”‚ Camera  â”‚   â”‚   Face    â”‚  â”‚ Rendering â”‚
    â”‚ Manager â”‚   â”‚  Tracker  â”‚  â”‚  Engine   â”‚
    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
         â”‚              â”‚              â”‚
         â”‚              â”‚              â”‚
    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚              Component Details                     â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚ CameraManager:                                     â”‚
    â”‚  â€¢ getUserMedia API integration                    â”‚
    â”‚  â€¢ Stream management (640Ã—480, 'user' facing)     â”‚
    â”‚  â€¢ Error handling (permissions, not found)         â”‚
    â”‚                                                    â”‚
    â”‚ FaceTracker:                                       â”‚
    â”‚  â€¢ MediaPipe Face Mesh integration (CDN)          â”‚
    â”‚  â€¢ 468 landmark detection                          â”‚
    â”‚  â€¢ Direction calculation (threshold: 0.05)         â”‚
    â”‚  â€¢ EmojiMatcher integration                        â”‚
    â”‚                                                    â”‚
    â”‚ EmojiMatcher:                                      â”‚
    â”‚  â€¢ Facial metric calculation:                      â”‚
    â”‚    - Mouth openness, smile level                   â”‚
    â”‚    - Eyebrow raise, eye openness                   â”‚
    â”‚    - Mouth width, lip pucker, head tilt           â”‚
    â”‚  â€¢ 12 expression detection algorithms              â”‚
    â”‚  â€¢ 2-frame smoothing for stability                 â”‚
    â”‚                                                    â”‚
    â”‚ RenderingEngine:                                   â”‚
    â”‚  â€¢ Canvas 2D rendering                             â”‚
    â”‚  â€¢ 150+ landmark visualization                     â”‚
    â”‚  â€¢ Border color updates (CSS transitions)          â”‚
    â”‚  â€¢ Frame synchronization                           â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚              External Dependencies                 â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚ â€¢ MediaPipe Face Mesh (CDN)                       â”‚
    â”‚ â€¢ Browser APIs: getUserMedia, Canvas, WebAssembly â”‚
    â”‚ â€¢ TypeScript (ES6 modules)                        â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Data Flow:
1. Camera â†’ Video Stream â†’ FaceTracker
2. FaceTracker â†’ Landmarks + Direction â†’ EmojiMatcher
3. EmojiMatcher â†’ Expression + Emoji â†’ ApplicationController
4. ApplicationController â†’ State â†’ RenderingEngine
5. RenderingEngine â†’ Visual Output â†’ Canvas + UI Updates
```

## Component Architecture

### Core Components

1. **ApplicationController** (`src/ApplicationController.ts`)
   - Central orchestrator managing all components
   - Implements render loop with requestAnimationFrame
   - Manages application state and error handling
   - Coordinates camera, tracking, and rendering

2. **CameraManager** (`src/CameraManager.ts`)
   - Handles getUserMedia API for camera access
   - Manages video stream lifecycle
   - Error handling for permissions and device issues

3. **FaceTracker** (`src/FaceTracker.ts`)
   - Integrates MediaPipe Face Mesh
   - Processes video frames to extract 468 landmarks
   - Calculates head direction (LEFT/RIGHT/UP/DOWN/CENTER)
   - Uses EmojiMatcher for expression detection

4. **EmojiMatcher** (`src/EmojiMatcher.ts`)
   - Analyzes facial landmarks for expression metrics
   - Detects 12 different expressions
   - Implements smoothing algorithm (2-frame stability)
   - Maps expressions to emoji characters

5. **RenderingEngine** (`src/RenderingEngine.ts`)
   - Renders video feed and landmark overlays
   - Updates border colors based on direction
   - Draws 150+ key facial landmarks
   - Manages canvas 2D context

### Configuration

**AppConfig** (`src/AppConfig.ts`)
- Camera settings (640Ã—480, 'user' facing mode)
- Tracking thresholds (detection: 0.5, tracking: 0.5, direction: 0.05)
- Rendering settings (30 FPS target, landmark colors)
- Border color mappings for each direction

## Setup

### Local Development

1. Install dependencies:
```bash
npm install
```

2. Build the TypeScript code:
```bash
npm run build
```

3. Serve the application:
```bash
npm start
# or
./serve.sh
```

4. Open browser to `http://localhost:8000`

5. Allow camera permissions when prompted

**Note:** Camera access requires HTTPS except on localhost.

### AWS Deployment

Deploy to S3 + CloudFront in eu-central-1:

```bash
./deploy.sh
```

The script will:
- Build the TypeScript application
- Create/update CloudFormation stack
- Sync files to S3 bucket
- Invalidate CloudFront cache
- Output the website URL

## Development

- **Build**: `npm run build` - Compile TypeScript to JavaScript
- **Watch mode**: `npm run dev` - Auto-rebuild on file changes
- **Run tests**: `npm test` - Execute Jest test suite (15 tests)
- **Serve locally**: `npm start` or `./serve.sh` - Start local server

## How It Works

1. **Camera Initialization**: Requests camera access via getUserMedia API
2. **Face Detection**: MediaPipe Face Mesh detects face and extracts 468 landmarks
3. **Expression Analysis**: EmojiMatcher calculates facial metrics (mouth, eyes, eyebrows)
4. **Direction Calculation**: Compares nose position to face center with 0.05 threshold
5. **Rendering**: Draws video feed, 150+ landmarks, and updates UI
6. **Collection Game**: Detects expressions, increments counters (throttled to 1/second)

## Expression Detection

The application detects 12 expressions using facial landmark analysis:

| Expression | Emoji | Detection Method |
|------------|-------|------------------|
| Neutral | ğŸ˜ | Baseline state |
| Happy | ğŸ™‚ | Smile level > 0.025 |
| Very Happy | ğŸ˜„ | Smile level > 0.045 + wide mouth |
| Sad | ğŸ˜¢ | Smile level < -0.015 (frown) |
| Surprised | ğŸ˜® | Mouth open + eyebrows raised |
| Angry | ğŸ˜  | Eyebrows down + slight frown |
| Wink | ğŸ˜‰ | One eye closed, other open |
| Kiss | ğŸ˜˜ | Lips puckered + narrow mouth |
| Tongue Out | ğŸ˜› | Very wide mouth + specific shape |
| Thinking | ğŸ¤” | Head tilt + slight eyebrow raise |
| Sleepy | ğŸ˜´ | Both eyes partially closed |
| Confused | ğŸ˜• | Eyebrows raised + neutral mouth |

## Technology Stack

- **TypeScript** - Type-safe development with ES6 modules
- **MediaPipe Face Mesh** - 468-point facial landmark detection (loaded via CDN)
- **HTML5 Canvas API** - 2D rendering for video and landmarks
- **Jest** - Unit testing framework
- **fast-check** - Property-based testing library
- **AWS CloudFormation** - Infrastructure as code
- **AWS S3 + CloudFront** - Static hosting with CDN

## Project Structure

```
.
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.ts                    # Application entry point
â”‚   â”œâ”€â”€ ApplicationController.ts   # Main orchestrator
â”‚   â”œâ”€â”€ CameraManager.ts          # Camera access management
â”‚   â”œâ”€â”€ FaceTracker.ts            # Face detection & tracking
â”‚   â”œâ”€â”€ EmojiMatcher.ts           # Expression detection
â”‚   â”œâ”€â”€ RenderingEngine.ts        # Canvas rendering
â”‚   â””â”€â”€ AppConfig.ts              # Configuration constants
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ FaceTracker.test.ts       # Unit tests (15 tests)
â”œâ”€â”€ dist/                          # Compiled JavaScript output
â”œâ”€â”€ index.html                     # Main HTML page
â”œâ”€â”€ styles.css                     # Responsive CSS styling
â”œâ”€â”€ cloudformation-template.yaml   # AWS infrastructure
â”œâ”€â”€ deploy.sh                      # Deployment script
â””â”€â”€ package.json                   # Dependencies & scripts
```

## Browser Requirements

- Modern browser with WebRTC support (Chrome, Firefox, Safari, Edge - latest versions)
- Camera access permission
- WebAssembly support (required by MediaPipe)
- JavaScript enabled
- Minimum screen resolution: 480px width

## Performance

- **Target FPS**: 30 frames per second
- **Landmark Rendering**: 150+ key points (optimized from 468 total)
- **Frame Budget**: 33ms per frame with automatic skipping if exceeded
- **Recognition Throttle**: 1 second between expression detections
- **Smoothing**: 2-frame stability requirement for expression changes

## Testing

The application includes comprehensive unit tests:

```bash
npm test
```

**Test Coverage:**
- Direction calculation (CENTER, LEFT, RIGHT, UP, DOWN)
- Landmark validation and normalization
- Threshold testing for direction detection
- Face center calculation
- Offset calculations (horizontal and vertical)
- Priority logic (horizontal vs vertical movement)

All 15 tests validate core face tracking logic.

## Troubleshooting

### Camera not working
- Check browser permissions (allow camera access)
- Ensure HTTPS connection (or use localhost)
- Verify camera is not in use by another application

### Direction not updating
- Ensure threshold is set to 0.05 in AppConfig
- Check that face is fully visible in frame
- Verify good lighting conditions

### Expressions not detected
- Ensure face is well-lit and fully visible
- Try exaggerated expressions
- Check that MediaPipe model loaded successfully
- Verify 2-frame smoothing is working (prevents flickering)

### Build errors
- Run `npm install` to ensure dependencies are installed
- Check TypeScript version compatibility
- Verify .js extensions in import statements (required for ES6 modules)

### Deployment fails
- Verify AWS credentials are configured
- Check that region is set to eu-central-1
- Ensure S3 bucket name is unique (uses account ID)
- Verify CloudFormation stack permissions

## Privacy

All video processing happens locally in your browser. No data is sent to any server.

- âœ… Client-side processing only
- âœ… No video recording or storage
- âœ… No data transmission to external servers
- âœ… MediaPipe model loaded from CDN but processing is local
- âœ… Camera access only when explicitly granted

## Key Implementation Details

### Direction Detection
- Uses nose tip (landmark 1) relative to face center
- Threshold: 0.05 for both horizontal and vertical offsets
- Corrects for camera mirror effect (negative offset = right, positive = left)
- Prioritizes larger offset when both horizontal and vertical movement detected

### Expression Detection
- Multi-point averaging for accuracy (4 points per eye, 3 per eyebrow)
- Calculates 7 facial metrics: mouth openness, smile level, eyebrow raise, eye openness, mouth width, lip pucker, head tilt
- 2-frame smoothing prevents flickering between expressions
- Fine-tuned thresholds for each of 12 expressions

### Responsive Design
- Viewport-fitted layout (100vh with overflow handling)
- Fixed 2Ã—6 emoji grid at all breakpoints
- Canvas scales proportionally with max dimensions
- Breakpoints: 1200px, 768px, 480px
- Emoji sizes adjust: 2rem â†’ 1.75rem â†’ 1.5rem â†’ 1.25rem

## Contributing

This project was built as a learning exercise following the spec-driven development methodology. The complete requirements, design, and implementation plan are available in `.kiro/specs/orientation-estimator-app/`.

## License

MIT

## Acknowledgments

- MediaPipe Face Mesh by Google for facial landmark detection
- Built with TypeScript and modern web APIs
- Deployed on AWS infrastructure
